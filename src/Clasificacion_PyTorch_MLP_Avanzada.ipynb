{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd18d780",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes con PyTorch y MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5dd73",
   "metadata": {},
   "source": [
    "Adapto el modelo simple para que se pueda usar con el dataset de Split_smol y le agrego un par de modificaciones para complejizarlo y volverlo más eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f843a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.2254, val_loss=1.9371, val_acc=0.4420\n",
      "Epoch 2: train_loss=1.7873, val_loss=1.6101, val_acc=0.4807\n",
      "Epoch 3: train_loss=1.6657, val_loss=1.4576, val_acc=0.4751\n",
      "Epoch 4: train_loss=1.4957, val_loss=1.3797, val_acc=0.5193\n",
      "Epoch 5: train_loss=1.3663, val_loss=1.3160, val_acc=0.5028\n",
      "Epoch 6: train_loss=1.2932, val_loss=1.3240, val_acc=0.4972\n",
      "Epoch 7: train_loss=1.2585, val_loss=1.2185, val_acc=0.5359\n",
      "Epoch 8: train_loss=1.2113, val_loss=1.1601, val_acc=0.5967\n",
      "Epoch 9: train_loss=1.0887, val_loss=1.1198, val_acc=0.5691\n",
      "Epoch 10: train_loss=1.0403, val_loss=1.1311, val_acc=0.5580\n"
     ]
    }
   ],
   "source": [
    "# Clasificación de imágenes con MLP y PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_class(x):\n",
    "    return str(x.parent).split(\"/\")[-1]\n",
    "\n",
    "# Transformaciones con Albumentations\n",
    "def get_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(64, 64),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "class AlbumentationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        # Create a mapping from class name to integer label\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(sorted(self.dataframe['class'].unique()))}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        img = np.array(Image.open(row['path']).convert('RGB'))\n",
    "        label = self.class_to_idx[row['class']]\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "# Modelo MLP con BatchNorm y Dropout\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features=3*64*64, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "# Entrenamiento\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Validación\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item()\n",
    "            preds = output.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), acc\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = get_transforms()\n",
    "\n",
    "    # train_base = CIFAR10(root='./data', train=True, download=True)\n",
    "    # test_base = CIFAR10(root='./data', train=False, download=True)\n",
    "    data_dir = r'data/Split_smol/train/'\n",
    "    p = Path(data_dir).glob('**/*')\n",
    "    files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "    train_base = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\",\"data\"])\n",
    "    data_dir = r'data/Split_smol/val/'\n",
    "    p = Path(data_dir).glob('**/*')\n",
    "    files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "    test_base = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\",\"data\"])\n",
    "\n",
    "    train_dataset = AlbumentationsDataset(train_base, transform)\n",
    "    test_dataset = AlbumentationsDataset(test_base, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "    model = MLP().to(device)\n",
    "    model.init_weights()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param, epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5510cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
