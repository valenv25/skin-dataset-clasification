{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d80d810",
   "metadata": {},
   "source": [
    "# Clasificación de imágenes con PyTorch y MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7f422",
   "metadata": {},
   "source": [
    "## Modelo Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99449de6-85e8-41e9-b4ea-7e50866d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eea338-d373-4d32-8815-54ba0a156e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 04:07:07 INFO mlflow.tracking.fluent: Experiment with name 'MLP_Clasificador_Imagenes' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/valen/Storage/ITBA/20251Q/Redes/test/old/mlruns/503415633472286498', creation_time=1750230427408, experiment_id='503415633472286498', last_update_time=1750230427408, lifecycle_stage='active', name='MLP_Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# End any active MLflow run before starting a new one\n",
    "if mlflow.active_run() is not None:\n",
    "\tmlflow.end_run()\n",
    "mlflow.set_experiment(\"MLP_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21eeefb-bc83-4931-acbc-65ca26d10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d2f49-abfd-444a-a947-712c1737eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para loguear una figura matplotlib en TensorBoard\n",
    "def plot_to_tensorboard(fig, writer, tag, step):\n",
    "\tbuf = io.BytesIO()\n",
    "\tfig.savefig(buf, format='png')\n",
    "\tbuf.seek(0)\n",
    "\timage = Image.open(buf).convert(\"RGB\")\n",
    "\timage = np.array(image)\n",
    "\timage = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "\twriter.add_image(tag, image, global_step=step)\n",
    "\tplt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901b00e-6c31-4af2-ab6d-1cc383687d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para matriz de confusión y clasificación\n",
    "def log_classification_report(model, loader, writer, step, prefix=\"val\"):\n",
    "\tmodel.eval()\n",
    "\tall_preds = []\n",
    "\tall_labels = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in loader:\n",
    "\t\t\timages = images.to(device)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tall_preds.extend(preds.cpu().numpy())\n",
    "\t\t\tall_labels.extend(labels.numpy())\n",
    "\n",
    "\t# Confusion matrix\n",
    "\tcm = confusion_matrix(all_labels, all_preds)\n",
    "\tfig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "\tdisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.label_encoder.classes_)\n",
    "\tdisp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "\tax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "\t# Guardar localmente y subir a MLflow\n",
    "\tfig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "\tfig_cm.savefig(fig_path)\n",
    "\tmlflow.log_artifact(fig_path)\n",
    "\tos.remove(fig_path)\n",
    "\n",
    "\tplot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "\tcls_report = classification_report(all_labels, all_preds, target_names=train_dataset.label_encoder.classes_)\n",
    "\twriter.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "\t# También loguear texto del reporte\n",
    "\twith open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "\t\tf.write(cls_report)\n",
    "\tmlflow.log_artifact(f.name)\n",
    "\tos.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6564e0-f970-461a-8ab4-5d19e0d55040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs\n",
    "log_dir = \"runs/mlp_experimento_1\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41919c3b-76d8-4eb0-810a-62ce743752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "\tdef __init__(self, root_dir, transform=None):\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\t\tself.image_paths = []\n",
    "\t\tself.labels = []\n",
    "\n",
    "\t\tclass_names = sorted(os.listdir(root_dir))\n",
    "\t\tself.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "\t\tfor cls in class_names:\n",
    "\t\t\tcls_dir = os.path.join(root_dir, cls)\n",
    "\t\t\tfor fname in os.listdir(cls_dir):\n",
    "\t\t\t\tif fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "\t\t\t\t\tself.image_paths.append(os.path.join(cls_dir, fname))\n",
    "\t\t\t\t\tself.labels.append(cls)\n",
    "\n",
    "\t\tself.label_encoder = LabelEncoder()\n",
    "\t\tself.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.image_paths)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "\t\tlabel = self.labels[idx]\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\taugmented = self.transform(image=image)\n",
    "\t\t\timage = augmented[\"image\"]\n",
    "\n",
    "\t\treturn image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0d2e4-319e-4f95-a59b-565182681864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "\tA.Resize(64, 64),\n",
    "\tA.HorizontalFlip(p=0.5),\n",
    "\tA.RandomBrightnessContrast(p=0.2),\n",
    "\tA.Normalize(),\n",
    "\tToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32743888-c68f-4a1a-a5e0-afe766b91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = A.Compose([\n",
    "\tA.Resize(64, 64),\n",
    "\tA.Normalize(),\n",
    "\tToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a707a13e-87cc-4c2b-89fd-b83ff1fd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e18375e-9fb1-4084-8338-302ca99f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d4d33-e68d-4ccb-8b0e-f18deabc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "\tdef __init__(self, input_size=64*64*3, num_classes=10):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(input_size, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(128, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b8088-283f-4549-8c86-2fec28283e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, epoch=None, prefix=\"val\"):\n",
    "\tlog_classification_report(model, val_loader, writer, step=epoch, prefix=\"val\")\n",
    "\tmodel.eval()\n",
    "\tcorrect, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "\tall_preds = []\n",
    "\tall_labels = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, (images, labels) in enumerate(loader):\n",
    "\t\t\timages, labels = images.to(device), labels.to(device)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\n",
    "\t\t\tloss_sum += loss.item()\n",
    "\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\n",
    "\t\t\tall_preds.extend(preds.cpu().numpy())\n",
    "\t\t\tall_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\t\t\t# Loguear imágenes del primer batch\n",
    "\t\t\tif i == 0 and epoch is not None:\n",
    "\t\t\t\timg_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "\t\t\t\twriter.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "\tacc = 100.0 * correct / total\n",
    "\tavg_loss = loss_sum / len(loader)\n",
    "\n",
    "\tif epoch is not None:\n",
    "\t\twriter.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "\t\twriter.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "\treturn avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d5e76-139b-43b0-a5f0-a781b0a22463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 22/22 [00:13<00:00,  1.67it/s]\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 2.8399, Accuracy: 26.11%\n",
      "  Val   Loss: 1.8854, Accuracy: 37.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 22/22 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 1.8681, Accuracy: 39.31%\n",
      "  Val   Loss: 1.8871, Accuracy: 35.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 22/22 [00:05<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 1.5531, Accuracy: 45.05%\n",
      "  Val   Loss: 1.3917, Accuracy: 50.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 22/22 [00:06<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 1.2979, Accuracy: 53.37%\n",
      "  Val   Loss: 1.2783, Accuracy: 52.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 22/22 [00:05<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 1.1456, Accuracy: 55.81%\n",
      "  Val   Loss: 1.3216, Accuracy: 47.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 22/22 [00:05<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 1.1186, Accuracy: 58.11%\n",
      "  Val   Loss: 1.2882, Accuracy: 49.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 22/22 [00:05<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 1.0056, Accuracy: 58.82%\n",
      "  Val   Loss: 1.1191, Accuracy: 61.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 22/22 [00:05<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 1.0012, Accuracy: 61.84%\n",
      "  Val   Loss: 1.2247, Accuracy: 56.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 22/22 [00:06<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 0.9597, Accuracy: 64.56%\n",
      "  Val   Loss: 1.1891, Accuracy: 57.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 22/22 [00:05<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 0.9509, Accuracy: 63.13%\n",
      "  Val   Loss: 1.2390, Accuracy: 56.91%\n"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento\n",
    "n_epochs = 10\n",
    "\n",
    "# End any active MLflow run before starting a new one\n",
    "# if mlflow.active_run() is not None:\n",
    "#     mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "\t# Log hiperparámetros\n",
    "\tmlflow.log_params({\n",
    "\t\t\"model\": \"MLPClassifier\",\n",
    "\t\t\"input_size\": 64*64*3,\n",
    "\t\t\"batch_size\": batch_size,\n",
    "\t\t\"lr\": 1e-3,\n",
    "\t\t\"epochs\": n_epochs,\n",
    "\t\t\"optimizer\": \"Adam\",\n",
    "\t\t\"loss_fn\": \"CrossEntropyLoss\",\n",
    "\t\t\"train_dir\": train_dir,\n",
    "\t\t\"val_dir\": val_dir,\n",
    "\t})\n",
    "\tfor epoch in range(n_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tcorrect, total = 0, 0\n",
    "\n",
    "\t\tfor images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "\t\t\timages, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\n",
    "\t\ttrain_loss = running_loss / len(train_loader)\n",
    "\t\ttrain_acc = 100.0 * correct / total\n",
    "\t\tval_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\n",
    "\t\tprint(f\"Epoch {epoch+1}:\")\n",
    "\t\tprint(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\t\tprint(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "\t\twriter.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "\t\twriter.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "\n",
    "\t\t# Log en MLflow\n",
    "\t\tmlflow.log_metrics({\n",
    "\t\t\t\"train_loss\": train_loss,\n",
    "\t\t\t\"train_accuracy\": train_acc,\n",
    "\t\t\t\"val_loss\": val_loss,\n",
    "\t\t\t\"val_accuracy\": val_acc\n",
    "\t\t}, step=epoch)\n",
    "\n",
    "\t# Guardar modelo\n",
    "\ttorch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "\tprint(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "\tmlflow.log_artifact(\"mlp_model.pth\")\n",
    "\tmlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "\tprint(\"Modelo guardado como 'mlp_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "551ce1c4-58b3-4abf-8eb7-107b760ba69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 21764), started 0:01:14 ago. (Use '!kill 21764' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-99f4d94dd3b5f585\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-99f4d94dd3b5f585\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs/mlp_experimento_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d6d98",
   "metadata": {},
   "source": [
    "## Actividades de modificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1c5135",
   "metadata": {},
   "source": [
    "### 7. Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51795cd",
   "metadata": {},
   "source": [
    "MLP con Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d99a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDropout(nn.Module):\n",
    "\tdef __init__(self, input_size=64*64*3, num_classes=10, p=0.5):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(input_size, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p),\n",
    "\t\t\tnn.Linear(512, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p),\n",
    "\t\t\tnn.Linear(128, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb5013",
   "metadata": {},
   "source": [
    "MLP con BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBatchNorm(nn.Module):\n",
    "\tdef __init__(self, input_size=64*64*3, num_classes=10):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(input_size, 512),\n",
    "\t\t\tnn.BatchNorm1d(512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 128),\n",
    "\t\t\tnn.BatchNorm1d(128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(128, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fdc0c",
   "metadata": {},
   "source": [
    "MLP con BatchNorm y Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26129463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBatchNormDropout(nn.Module):\n",
    "\tdef __init__(self, input_size=64*64*3, num_classes=10, p=0.5):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(input_size, 512),\n",
    "\t\t\tnn.BatchNorm1d(512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p),\n",
    "\t\t\tnn.Linear(512, 128),\n",
    "\t\t\tnn.BatchNorm1d(128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p),\n",
    "\t\t\tnn.Linear(128, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\n",
    "# Hay que agregar:\n",
    "# mlflow.log_param(\"batchnorm\", True)\n",
    "# mlflow.log_param(\"dropout_p\", 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e682d8",
   "metadata": {},
   "source": [
    "Optimizer con Weight Decay (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17355fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Hay que agregar:\n",
    "# mlflow.log_param(\"weight_decay\", 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d39cb",
   "metadata": {},
   "source": [
    "Data Augmentation avanzado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d5b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_transform_adv = A.Compose([\n",
    "\tA.Resize(64, 64),\n",
    "\tA.HorizontalFlip(p=0.5),\n",
    "\t# A.VerticalFlip(p=0.5),\n",
    "\tA.RandomBrightnessContrast(p=0.2),\n",
    "\tA.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "\t# A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "\tA.Normalize(),\n",
    "\tToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset_adv = CustomImageDataset(train_dir, transform=train_transform_adv)\n",
    "train_loader_adv = DataLoader(train_dataset_adv, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa44f1",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valen\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping en epoch 4\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\t# Train...\n",
    "\tval_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\tif val_loss < best_val_loss:\n",
    "\t\tbest_val_loss = val_loss\n",
    "\t\tcounter = 0\n",
    "\t\ttorch.save(model.state_dict(), \"best_model.pth\")\n",
    "\telse:\n",
    "\t\tcounter += 1\n",
    "\t\tif counter >= patience:\n",
    "\t\t\tprint(f\"Early stopping en epoch {epoch+1}\")\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26e513",
   "metadata": {},
   "source": [
    "### 8. Inicialización de Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización manual de pesos\n",
    "class MLPInit(nn.Module):\n",
    "\tdef __init__(self, input_size=64*64*3, num_classes=10, init_type='he'):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(input_size, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(128, num_classes)\n",
    "\t\t)\n",
    "\t\tself.init_weights(init_type)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\n",
    "\tdef init_weights(self, init_type):\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\t\tif init_type == 'he':\n",
    "\t\t\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\t\t\t\telif init_type == 'xavier':\n",
    "\t\t\t\t\tnn.init.xavier_uniform_(m.weight)\n",
    "\t\t\t\tif m.bias is not None:\n",
    "\t\t\t\t\tnn.init.zeros_(m.bias)\n",
    "\n",
    "# Hay que agregar:\n",
    "# mlflow.log_param(\"init_type\", \"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63959672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de pesos\n",
    "for name, param in model.named_parameters():\n",
    "\tif 'weight' in name:\n",
    "\t\twriter.add_histogram(name, param, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui # http://localhost:5000\n",
    "!tensorboard --logdir=runs # http://localhost:6006\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# results = pd.read_csv(\"resultados_experimentos.csv\")\n",
    "# display(results.sort_values(\"val_accuracy\", ascending=False))\n",
    "# variantes = [\"Base\", \"Dropout\", \"BatchNorm\", \"Dropout+BatchNorm\", \"Init He\", \"Init Xavier\", \"L2\", \"Augment\", \"Grises\"]\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.bar(variantes, results.sort_values(\"val_accuracy\", ascending=False)[\"val_accuracy\"], color='skyblue')\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.title(\"Comparación de variantes MLP\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variantes = [\n",
    "\t\"base\",\n",
    "\t# \"pocas_imagenes\",\n",
    "\t# \"grises\",\n",
    "\t\"dropout\",\n",
    "\t\"batchnorm\",\n",
    "\t\"batchnorm_dropout\",\n",
    "\t\"weight_decay\",\n",
    "\t\"augmentation\",\n",
    "\t\"init_he\",\n",
    "\t\"init_xavier\",\n",
    "\t\"histogramas\"\n",
    "]\n",
    "\n",
    "for var in variantes:\n",
    "\tprint(f\"Entrenando variante: {var}\")\n",
    "\t\n",
    "\tif var == \"base\" or var == \"weight_decay\" or var == \"augmentation\" or var == \"histogramas\":\n",
    "\t\tmodel = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\t# elif var == \"grises\":\n",
    "\t# elif var == \"pocas_imagenes\":\n",
    "\telif var == \"init_he\":\n",
    "\t\tmodel = MLPInit(init_type='he', num_classes=num_classes).to(device)\n",
    "\telif var == \"init_xavier\":\n",
    "\t\tmodel = MLPInit(init_type='xavier', num_classes=num_classes).to(device)\n",
    "\telif var == \"dropout\":\n",
    "\t\tmodel = MLPDropout(num_classes=num_classes).to(device)\n",
    "\telif var == \"batchnorm\":\n",
    "\t\tmodel = MLPBatchNorm(num_classes=num_classes).to(device)\n",
    "\telif var == \"batchnorm_dropout\":\n",
    "\t\tmodel = MLPBatchNormDropout(num_classes=num_classes).to(device)\n",
    "\telse:\n",
    "\t\traise ValueError(f\"Variante '{var}' no reconocida.\")\n",
    "\n",
    "\tif var == \"weight_decay\":\n",
    "\t\toptimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\telse:\n",
    "\t\toptimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\tif var == \"augmentation\":\n",
    "\t\ttrain_loader = train_loader_adv\n",
    "\n",
    "\twriter = SummaryWriter(log_dir=f\"runs/experimento_{var}\")\n",
    "\t\n",
    "\tfor epoch in range(n_epochs):\n",
    "\t\t# Train...\n",
    "\t\t# writer.add_scalar(...)\n",
    "\t\tif var == \"histogramas\":\n",
    "\t\t\t# Histogramas de pesos\n",
    "\t\t\tfor name, param in model.named_parameters():\n",
    "\t\t\t\tif 'weight' in name:\n",
    "\t\t\t\t\twriter.add_histogram(name, param, epoch)\n",
    "\t\n",
    "\ttorch.save(model.state_dict(), f\"mlp_{var}.pth\")\n",
    "\tmlflow.log_param(\"variante\", var)\n",
    "\tmlflow.log_artifact(f\"mlp_{var}.pth\")\n",
    "\t\n",
    "\twriter.close()\n",
    "\tprint(f\"Variante {var} entrenada y guardada.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
