{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce9329-dfa9-4c9a-a759-43075605a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io\n",
    "from helper import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ee6d-5ae2-4750-b49b-b343f19c9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb85e50-d8ea-4a0d-82b8-dfbfa12ef379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb67cc-e660-4822-a999-ff80aa316a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1b529-ba09-4afc-a901-b04b3c07ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End any active MLflow run before starting a new one\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "mlflow.set_experiment(\"Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135b655-4342-4c85-9c68-46ef459de7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_classification_report(model, loader, writer, device, classes, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a152ed-69db-408c-9920-980b864416b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, writer, device, classes, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, loader, writer, device, classes, step=epoch , prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acfa65-34ab-454c-ba1a-b2f8f1f99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"../../data/Split_smol/train\"\n",
    "val_dir = \"../../data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d4782-1460-4d63-b282-14ac74d1587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs de tensorboard\n",
    "log_dir = \"runs/experimento_skin\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b2f89-33be-4c4f-a499-8704987249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b58ed-4d28-431f-a8be-2549a20402cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"CNNClassifier\"),\n",
    "    \"input_size\":  [32,64,128],\n",
    "    \"batch_size\": [16,64,128],\n",
    "    \"lr\": [1e-2,1e-3,1e-4],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\", \"SGD\"],\n",
    "    \"HFlip\": [0.0,0.5],\n",
    "    \"VFlip\": [0.0,0.5],\n",
    "    \"RBContrast\": [0.0, 0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"val_dir\": val_dir,\n",
    "    \"es_patience\": 5,\n",
    "    \"dropout\": [0.0, 0.1,0.2,0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"CNNClassifier\"),\n",
    "    \"input_size\":  [32],\n",
    "    \"batch_size\": [64],\n",
    "    \"lr\": [1e-4],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\"],\n",
    "    \"HFlip\": [0.5],\n",
    "    \"VFlip\": [0.5],\n",
    "    \"RBContrast\": [0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"val_dir\": val_dir,\n",
    "    \"es_patience\": 5,\n",
    "    \"dropout\": [0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1097b11-4a9a-402e-b238-6acfe506a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnbr = 0\n",
    "for input_size in hparams_space[\"input_size\"]:\n",
    "    for batch_size in hparams_space[\"batch_size\"]:\n",
    "        for lr in hparams_space[\"lr\"]:\n",
    "            for optimizer in hparams_space[\"optimizer\"]:\n",
    "                for HFlip in hparams_space[\"HFlip\"]:\n",
    "                    for VFlip in hparams_space[\"VFlip\"]:\n",
    "                        for RBContrast in hparams_space[\"RBContrast\"]:\n",
    "                            for dropout in hparams_space[\"dropout\"]:\n",
    "                                if np.random.rand() < 1:\n",
    "                                    print(f\"modelo número: {modelnbr}\", end = \"\\r\")\n",
    "                                    modelnbr += 1\n",
    "                                    hparams= {\n",
    "                                        \"model\": (\"CNNClassifier\"),\n",
    "                                        \"input_size\":  input_size,\n",
    "                                        \"batch_size\": batch_size,\n",
    "                                        \"lr\": lr,\n",
    "                                        \"epochs\": 200,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"HFlip\": HFlip,\n",
    "                                        \"VFlip\": VFlip,\n",
    "                                        \"RBContrast\": RBContrast,\n",
    "                                        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "                                        \"train_dir\": train_dir,\n",
    "                                        \"val_dir\": val_dir,\n",
    "                                        \"es_patience\": 5,\n",
    "                                        \"dropout\": dropout,\n",
    "                                    }\n",
    "                                    train_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "                                        A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "                                        A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    val_test_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "                                    val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "                                    batch_size = hparams[\"batch_size\"]\n",
    "                                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                    val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                    num_classes = len(set(train_dataset.labels))\n",
    "                                    model = CNNClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"], dropout = hparams[\"dropout\"]).to(device)\n",
    "                                    criterion = nn.CrossEntropyLoss()\n",
    "                                    optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"]) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "                                    hparams[\"count_params\"] = count_parameters(model)\n",
    "                                    with mlflow.start_run():\n",
    "                                        # Log hiperparámetros\n",
    "                                        mlflow.log_params(hparams)\n",
    "                                        best_val_acc = 0\n",
    "                                        best_val_loss = 0\n",
    "                                        best_train_acc = 0\n",
    "                                        best_train_loss = 0\n",
    "                                        best_epoch = 0\n",
    "                                        for epoch in range(hparams[\"epochs\"]):\n",
    "                                            model.train()\n",
    "                                            running_loss = 0.0\n",
    "                                            correct, total = 0, 0\n",
    "                                        \n",
    "                                            for images, labels in train_loader:\n",
    "                                                images, labels = images.to(device), labels.to(device)\n",
    "                                        \n",
    "                                                optimizer.zero_grad()\n",
    "                                                outputs = model(images)\n",
    "                                                loss = criterion(outputs, labels)\n",
    "                                                loss.backward()\n",
    "                                                optimizer.step()\n",
    "                                        \n",
    "                                                running_loss += loss.item()\n",
    "                                                _, preds = torch.max(outputs, 1)\n",
    "                                                correct += (preds == labels).sum().item()\n",
    "                                                total += labels.size(0)\n",
    "                                        \n",
    "                                            train_loss = running_loss / len(train_loader)\n",
    "                                            train_acc = 100.0 * correct / total\n",
    "                                            val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset.label_encoder.classes_,epoch=epoch, prefix=\"val\")\n",
    "                                        \n",
    "                                            #print(f\"Epoch {epoch+1}:\")\n",
    "                                            #print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "                                            #print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "                                        \n",
    "                                            writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "                                            writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "                                        \n",
    "                                            # Log en MLflow\n",
    "                                            mlflow.log_metrics({\n",
    "                                                \"train_loss\": train_loss,\n",
    "                                                \"train_accuracy\": train_acc,\n",
    "                                                \"val_loss\": val_loss,\n",
    "                                                \"val_accuracy\": val_acc\n",
    "                                            }, step=epoch)\n",
    "                                            if val_acc > best_val_acc:\n",
    "                                                best_val_acc = val_acc\n",
    "                                                best_val_loss = val_loss\n",
    "                                                best_train_acc = train_acc\n",
    "                                                best_train_loss = train_loss\n",
    "                                                best_epoch = epoch\n",
    "                                                # Guardar modelo\n",
    "                                                torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "                                                #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "                                                mlflow.log_artifact(\"mlp_model.pth\")\n",
    "                                                mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "                                            elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "                                                #print(\"Early Stopping\")\n",
    "                                                break\n",
    "                                                \n",
    "                                        mlflow.log_metrics({\n",
    "                                                \"train_loss\": best_train_loss,\n",
    "                                                \"train_accuracy\": best_train_acc,\n",
    "                                                \"val_loss\": best_val_loss,\n",
    "                                                \"val_accuracy\": best_val_acc,\n",
    "                                                \"best_epoch\": best_epoch\n",
    "                                            }, step=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow      -> http://localhost:5000\n",
    "# tensorboard -> http://localhost:6006\n",
    "\n",
    "!mlflow ui\n",
    "# load_ext tensorboard\n",
    "!tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
