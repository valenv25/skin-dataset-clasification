{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e527172",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes con PyTorch y MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532a4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5fe93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        img = np.array(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a4d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24212dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item()\n",
    "            preds = output.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6eba67",
   "metadata": {},
   "source": [
    "Uso un dataset de prueba (CIFAR-10) para probar la clasificación de imágenes con PyTorch y MLP simple. Se podría aplicar al dataset de Split_smol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c12424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [01:04<00:00, 2.64MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.7815, val_loss=1.5877, val_acc=0.4538\n",
      "Epoch 2: train_loss=1.5412, val_loss=1.5496, val_acc=0.4600\n",
      "Epoch 3: train_loss=1.4875, val_loss=1.5488, val_acc=0.4604\n",
      "Epoch 4: train_loss=1.4488, val_loss=1.6101, val_acc=0.4618\n",
      "Epoch 5: train_loss=1.4189, val_loss=1.5882, val_acc=0.4643\n",
      "Epoch 6: train_loss=1.3781, val_loss=1.5971, val_acc=0.4691\n",
      "Epoch 7: train_loss=1.3533, val_loss=1.4963, val_acc=0.5028\n",
      "Epoch 8: train_loss=1.3269, val_loss=1.5489, val_acc=0.4973\n",
      "Epoch 9: train_loss=1.2856, val_loss=1.5591, val_acc=0.4997\n",
      "Epoch 10: train_loss=1.2699, val_loss=1.5751, val_acc=0.4906\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    base_train = CIFAR10(root='./data', train=True, download=True)\n",
    "    base_test = CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "    train_dataset = AlbumentationsDataset(base_train, transform)\n",
    "    test_dataset = AlbumentationsDataset(base_test, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "    input_size = 3 * 64 * 64\n",
    "    hidden_size = 256\n",
    "    num_classes = 10\n",
    "\n",
    "    model = SimpleMLP(input_size, hidden_size, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Validation\", val_acc, epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904d06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
